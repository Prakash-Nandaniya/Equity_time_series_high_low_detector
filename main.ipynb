{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "0d027728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # webscraping_yahoo finance data\n",
    "\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# from bs4 import BeautifulSoup\n",
    "# import pandas as pd\n",
    "# import time\n",
    "\n",
    "# chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "# driver = webdriver.Chrome(options=chrome_options)\n",
    "# url = \"https://finance.yahoo.com/quote/AAPL/history/?period1=345479400&period2=1761924776\"\n",
    "\n",
    "# driver.get(url)\n",
    "# time.sleep(5)  # Wait for the dynamic table to load\n",
    "\n",
    "# soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "# # Correct table class selector based on your screenshot\n",
    "# table = soup.find('table', {'class': 'table yf-1jecxey noDl hideOnPrint'})\n",
    "# if table:\n",
    "#     # Parse headers\n",
    "#     headers = []\n",
    "#     thead = table.find('thead')\n",
    "#     if thead:\n",
    "#         for th in thead.find_all('th'):\n",
    "#             headers.append(th.text.strip())\n",
    "#     # If headers list is empty, try checking the first tr's td\n",
    "#     if not headers and thead:\n",
    "#         first_tr = thead.find('tr')\n",
    "#         if first_tr:\n",
    "#             for td in first_tr.find_all('td'):\n",
    "#                 headers.append(td.text.strip())\n",
    "\n",
    "#     # Parse rows\n",
    "#     rows = []\n",
    "#     tbody = table.find('tbody')\n",
    "#     for tr in tbody.find_all('tr'):\n",
    "#         row = []\n",
    "#         for td in tr.find_all('td'):\n",
    "#             row.append(td.text.strip())\n",
    "#         if row:\n",
    "#             rows.append(row)\n",
    "\n",
    "#     # Save to CSV\n",
    "#     df = pd.DataFrame(rows, columns=headers if headers else None)\n",
    "#     df.to_csv('yahoo_finance_AAPL_historical.csv', index=False)\n",
    "#     print(\"CSV file saved as yahoo_finance_AAPL_historical.csv.\")\n",
    "# else:\n",
    "#     print(\"Table not found.\")\n",
    "\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "0b9b8a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cleaning file\n",
    "\n",
    "# import pandas as pd\n",
    "# from datetime import datetime\n",
    "\n",
    "# # Read the CSV file\n",
    "# file_path = 'yahoo_finance_AAPL_historical.csv'\n",
    "# df = pd.read_csv(file_path)\n",
    "\n",
    "# # Remove rows that have 'Dividend' in any column\n",
    "# df = df[~df.apply(lambda row: row.astype(str).str.contains('Dividend').any(), axis=1)]\n",
    "\n",
    "# # Process each row\n",
    "# def clean_row(row):\n",
    "#     # Fix date format: \"Oct 31, 2025\" -> \"Oct-31-2025\"\n",
    "#     try:\n",
    "#         row[0] = datetime.strptime(row[0], \"%b %d, %Y\").strftime(\"%b-%d-%Y\")\n",
    "#     except Exception:\n",
    "#         pass  # Skip rows where date is not in expected format\n",
    "    \n",
    "#     # Clean volume: \"37,689,790\" -> 37689790 (on last col)\n",
    "#     try:\n",
    "#         volume_str = str(row[-1]).replace(\",\", \"\")\n",
    "#         if volume_str.isdigit():\n",
    "#             row[-1] = int(volume_str)\n",
    "#     except Exception:\n",
    "#         pass  # If conversion fails, leave as is\n",
    "#     return row\n",
    "\n",
    "# df = df.apply(clean_row, axis=1)\n",
    "\n",
    "# # Save the cleaned DataFrame back to the CSV file\n",
    "# df.to_csv(file_path, index=False)\n",
    "# print(\"Cleaned data saved to\", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "39e5d94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data reading\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "df = pd.read_csv('yahoo_finance_AAPL_historical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3229e961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date <class 'str'>\n",
      "Open <class 'numpy.float64'>\n",
      "High <class 'numpy.float64'>\n",
      "Low <class 'numpy.float64'>\n",
      "Close <class 'numpy.float64'>\n",
      "Adj_Close <class 'numpy.float64'>\n",
      "Volume <class 'numpy.float64'>\n",
      "Label <class 'str'>\n",
      "Date         0\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj_Close    0\n",
      "Volume       0\n",
      "Label        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_113245/4144968491.py:6: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  df.interpolate(method='linear', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# checking data types\n",
    "for col in df.columns:\n",
    "    print(col, type(df[col].iloc[0]))\n",
    "\n",
    "# null value handling\n",
    "df.interpolate(method='linear', inplace=True)\n",
    "null_counts = df.isnull().sum()\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a0f10dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved chart.csv successfully with columns: time, Open, High, Low, Close for date range 1981-06-27 to 2000-12-31\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df already exists and has 'Date', 'Open', 'High', 'Low', 'Close' columns\n",
    "\n",
    "start_date = \"1981-06-27\"\n",
    "end_date = \"2000-12-31\"\n",
    "\n",
    "df_filtered = df.copy()\n",
    "\n",
    "# Ensure correct data types\n",
    "df_filtered[\"Date\"] = pd.to_datetime(df_filtered[\"Date\"], errors=\"coerce\")\n",
    "numeric_cols = [\"Open\", \"High\", \"Low\", \"Close\"]\n",
    "df_filtered[numeric_cols] = df_filtered[numeric_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# Drop rows with missing or invalid data\n",
    "df_filtered = df_filtered.dropna(subset=[\"Date\"] + numeric_cols)\n",
    "\n",
    "# Filter by date range\n",
    "df_filtered = df_filtered[(df_filtered[\"Date\"] >= start_date) & (df_filtered[\"Date\"] <= end_date)]\n",
    "\n",
    "# Prepare and save data\n",
    "df_to_save = df_filtered[[\"Date\", \"Open\", \"High\", \"Low\", \"Close\",\"Label\"]].copy()\n",
    "df_to_save[\"Date\"] = df_to_save[\"Date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "df_to_save.rename(columns={\"Date\": \"time\"}, inplace=True)\n",
    "\n",
    "df_to_save.to_csv(\"chart.csv\", index=False)\n",
    "\n",
    "print(f\"✅ Saved chart.csv successfully with columns: time, Open, High, Low, Close for date range {start_date} to {end_date}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Equity",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
